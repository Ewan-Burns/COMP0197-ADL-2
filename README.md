# COMP0197: Weakly-supervised neural networks for segmentation

## Overview

Implements and evaluates a weakly-supervised segmentation framework based on Class Activation Maps (CAMs) and the Seed, Expand, Constrain (SEC) methodology. Also includes fully-supervised baseline models (U-Net and DeepLabV3) for comparison.

## Project Structure

-   `src/`:
    -   `MultiTargetOxfordPet.py`: Custom dataset class for handling different target types.
    -   `baseline/`: Implementations and training scripts for fully-supervised baselines (U-Net, DeepLabV3).
    -   `weakly_supervised/`: Implementation of the CAM+SEC weakly-supervised approach (ResNet, SEC loss, CAM generation).
    -   `utils/`: Utility functions (dataset transformations, Dice loss).
-   `data/`: Dataset (downnloaded).
-   `models/`: Saved model weights.

## Setup

1.  **Clone the repository:**
    ```bash
    git clone git@github.com:Ewan-Burns/COMP0197-ADL-2.git
    cd COMP0197-ADL-2
    ```
2.  **Activate the comp0197-cw1 Conda environment:**
    ```bash
    conda activate comp0197-cw1-pt
    ```
3.  **Install additional (development) dependencies:**
    ```bash
    pip install matplotlib tqdm
    ```

## Running the Code

All scripts should be run from the **root directory** of the project using the `python -m` flag, see the example below: 

```bash
python -m python -m src.baseline.train_unet
```

### 1. Train Fully-Supervised Baselines

These scripts train standard segmentation models using the full pixel-level segmentation masks provided in the Oxford-IIIT Pet dataset. They serve as a baseline for comparison with the later weakly-supervised approach. Both scripts train for a fixed num of epochs, save the trained model weights to the `./models/` directory and display some predictions post training.

**U-Net:**
Trains a U-Net model (common architecture for image segmentation), adapted here for the pet dataset. It uses a combination of Cross-Entropy Loss and Dice Loss for training.
```bash
python -m src.baseline.train_unet
```

**DeepLabV3:**
This script trains a DeepLabV3 model (architecture for semantic image segmentation) with a ResNet50 backbone (CNN acting as feature extractor). The final classification layer is adapted for the 3 classes (background, cat, dog). It also uses a combination of Cross-Entropy and Dice Loss.
```bash
python -m src.baseline.train_deeplabv3
```

### 2. Train Weakly-Supervised Model (ResNet + SEC)

This script implements the core weakly-supervised learning approach described in the project overview. It uses only image-level labels (presence of cat/dog) for supervision.
- Trains a `MultiHeadResNet` (`src/weakly_supervised/resnet.py`).
- Generates Class Activation Maps (CAMs) using the classification head.
- Trains the segmentation head using the SEC loss (`src/weakly_supervised/sec.py`), which incorporates:
    - Seed Loss: Matching CAM seeds.
    - Expand Loss: Using image-level labels to encourage class presence.
    - Constrain Loss: Refining predictions using DenseCRF based on image appearance.
The script trains for a fixed number of epochs and displays visualisations comparing the input image, the generated CAM, and the final predicted segmentation mask.
```bash
python -m src.weakly_supervised.train_resnet
```

### 3. Run GradCAM++ Visualisation Test

This script visualises CAMs generated by a standard ResNet18 using the `torchcam` library and applies CRF refinement.
```bash
python -m src.weakly_supervised.test_gradcamcpp
```

### 4. Evaluate Trained Models

After training a model and saving the weights (e.g., to `./models/unet_3_classes.pth`), you can evaluate its performance on the test set using the dedicated evaluation script:

```bash
python -m src.evaluate --model-type <model_type> --model-path <path_to_pth_file>
```

Replace `<model_type>` with one of `unet`, `deeplabv3`, or `resnet_sec`.
Replace `<path_to_pth_file>` with the actual path to the saved model weights.

The script will load the specified model, run it on the standard test split, and print the calculated mean Intersection over Union (mIoU) and mean Dice Score (mDice), which is equivalent to the mean F1 Score (mF1).

**Examples:**

Evaluating the baseline U-Net:
```bash
python -m src.evaluate --model-type unet --model-path ./models/unet_3_classes.pth
```

Evaluating the baseline DeepLabV3:
```bash
python -m src.evaluate --model-type deeplabv3 --model-path ./models/deep_lab_v3_3_classes.pth
```

Evaluating a weakly-supervised ResNet+SEC model (replace path with the actual saved file):
```bash
python -m src.evaluate --model-type resnet_sec --model-path ./models/weakly_sup_ep10_lr0.0001_a1.0_b1.0_g0.5.pth
```
